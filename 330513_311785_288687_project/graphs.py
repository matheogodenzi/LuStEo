import numpy as np
import matplotlib.pyplot as plt
import torch

metrics_evolution = np.loadtxt('deep_network_metrics.txt', delimiter=',')


# Accuracy plot for the training, validation and test datasets
plt.plot(metrics_evolution[:,0])
plt.plot(metrics_evolution[:,2])
plt.plot(metrics_evolution[:,4])
plt.legend(['training', 'validation', 'test'])
plt.xlabel('iterations')
plt.ylabel('accuracy [%]')
plt.title('Accuracy Evolution During Deep Learning Training')
plt.grid()
plt.show()

# f1 score plot for the training, validation and test datasets
plt.plot(metrics_evolution[:,1])
plt.plot(metrics_evolution[:,3])
plt.plot(metrics_evolution[:,5])
plt.legend(['training', 'validation', 'test'])
plt.xlabel('iterations')
plt.ylabel('f1 score')
plt.title('f1 Score Evolution During Deep Learning Training')
plt.grid()
plt.show()


# comparing accuracies for training, validation and test datasets hyperparameters
# self.acc_tr, self.f1_tr, self.acc_val, self.f1_val, self.acc_test, self.f1_test
# neurons(300, 50) lr = 1e-4  iterations = 500 : 91.07763615295481,0.8934765275580588,75.06112469437653,0.6732569470894039,90.1294498381877,0.8845061728464775 almost 300 seconds
# neurons(200, 60) lr = 1e-5  iterations = 500 : 75.55040556199305,0.7050812444687429,71.39364303178485,0.6113329873568146,78.80258899676376,0.7052683376000596 almost 300 seconds
# neurons(200, 60) lr = 1e-4  iterations = 500 : 90.38238702201622,0.8851064828541279,74.81662591687042,0.6684416202324076,88.83495145631068,0.8633273423901765 almost 300 seconds
# neurons(60, 200) lr = 1e-4  iterations = 500 : 90.57551178061027,0.8871263011777724,73.83863080684597,0.6590820725138922,88.67313915857605,0.8632715086737841 182 seconds
# neurons(50, 300) lr = 1e-4  iterations = 500 : 91.8115102356122,0.9042446830355007,75.30562347188264,0.6790791677375211,89.96763754045307,0.88189220411075 178 seconds
# neurons(40, 400) lr = 1e-4  iterations = 500 : 92.19775975280031,0.9069830214474521,74.81662591687042,0.6755072094802385,88.83495145631068,0.8643985532099674 176 seconds
# neurons(60, 400) lr = 1e-4  iterations = 500 : 91.61838547701815,0.9005674017583156,74.81662591687042,0.6719020730961262,89.80582524271844,0.8793455843733604 184 seconds
# neurons(100, 100) lr = 1e-4  iterations = 500 : 90.49826187717265,0.8861586698810462,74.81662591687042,0.670100752786535,87.37864077669903,0.8436771976829622 209 seconds
# neurons(90, 200) lr = 1e-4  iterations = 500 : 91.07763615295481,0.893696614350552,74.81662591687042,0.6723991546634894,88.67313915857605,0.8634697246303025 198 seconds
# neurons(100, 10) lr = 1e-4  iterations = 500 : 90.2665121668598,0.8841427711453314,73.83863080684597,0.6655194974996003,89.15857605177993,0.8743375797834522 208 seconds
# neurons(300, 10) lr = 1e-4  iterations = 500 : 86.44264194669756,0.8147833964500824,77.01711491442543,0.6782250328875407,85.27508090614887,0.7939647777890558 275 seconds
# neurons(400, 60) lr = 1e-4  iterations = 500 : 91.15488605639243,0.8946850446583113,75.30562347188264,0.6744962315613408,87.86407766990291,0.850345053541713 260.98 seconds
# neurons(300, 32) lr = 1e-4  iterations = 500 : 90.73001158748552,0.8897049742697737,74.81662591687042,0.6683806557562029,20.975609756097562,0.34677419354838707 272 seconds
# neurons(400) lr = 1e-4  iterations = 500 : 94.36075704905369,0.9352934685842567,76.5281173594132,0.7042372278763838,92.71844660194175,0.917887806130118 292 seconds
# neurons(48, 24, 12, 6) lr = 1e-3 iterations = 1000 : 99.22750096562379,0.9919482106725129,75.06112469437653,0.7144611470908657,89.15857605177993,0.8772578748105458 289 seconds
# neurons(400) lr = 1e-4  iterations = 500 : 92.39088451139436,0.9106045493319895,74.81662591687042,0.6739036426536426,91.42394822006473,0.9037702760677124 116 seconds
# neurons(35, 25, 15) lr = 1e-4  iterations = 500 : 85.55426805716493,0.8076505412255228,76.28361858190709,0.6708665913211368,83.1715210355987,0.7641580969514111 130 seconds
# neurons(55, 45, 35) lr = 1e-4  iterations = 500 : 78.71765160293549,0.6465556979192698,77.01711491442543,0.6487751500794366,78.4789644012945,0.636408113807574 153.41582798957825 seconds
# neurons(100, 200, 300) lr = 1e-4  iterations = 500 : 81.6917728852839,0.7464634221511209,77.26161369193154,0.6595362651397134,78.80258899676376,0.7112208428052231 312.9899260997772 seconds

# neurons(32) lr = 1e-4  iterations = 1000 : 99.65237543453071,0.9963843313384658,75.55012224938875,0.7123827892518428,90.29126213592232,0.8895476024913511 239 seconds
# neurons(32, 32) lr = 1e-3  iterations = 1000 : 99.6137504828119,0.9962338103297419,76.28361858190709,0.7156430953485441,89.64401294498381,0.8811546969142383 250 seconds
# neurons(32, 32, 32) lr = 1e-3  iterations = 1000 : 99.42062572421784,0.9934614092514706,77.75061124694376,0.7446911991290948,87.54045307443366,0.8573377491906323 264 seconds
# neurons(32, 32, 32, 32) lr = 1e-3  iterations = 1000 : 98.60950173812283,0.9842382311221042,77.99511002444987,0.7542515699096317,87.05501618122977,0.8500427112382756 258 seconds
# variations in the number of layers of scores for the training, validation and test datasets
layers = [1, 2, 3, 4]
test_f1 = np.array([0.8895476024913511, 0.8811546969142383, 0.8573377491906323, 0.8500427112382756])
test_accuracies = [90.29, 89.64, 87.54, 87.05]
times = [239, 250, 264, 258]


plt.plot(layers, test_f1*100, '--o')
plt.plot(layers, test_accuracies, '--o')
plt.legend(['test f1 scores','test accuracies'])
plt.xlabel('number of layers')
plt.ylabel('metrics [%]')
plt.title('Final Scores After 1000 Iterations')
plt.grid()
plt.show()


plt.plot(layers, times)
plt.legend(['training time'])
plt.xlabel('number of layers')
plt.ylabel('f1 score')
plt.title('Final f1 Score after 1000 iterations')
plt.grid()
plt.show()
'''saving the result for the competition'''
#np.save("results_class", torch.load("results_class.txt").numpy())
